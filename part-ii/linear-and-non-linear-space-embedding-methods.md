# Linear and non-linear space embedding methods

When the dimensionality of the data is pretty high even before performing feature extraction, techniques like PCA\(Principal Component Analysis\), LDA\(Linear Discriminant Analysis\) and MDS\(Multidimensional scaling\) are used to project or embedded the data into lower dimensional space while retaining as much information as possible. These techniques are discussed in more detail later in this book.

While performing these methods, one needs to be aware not to lose any information. It may be a good idea to add the raw features to the preprocessed data or at least to compare the performances obtained with either representation. _It is better to err on the side of being too inclusive rather than risking to discard useful information._

Some methods to perform dimensionality reduction are:

* **Principal component analysis \(PCA\)**
* **Non-negative matrix factorization \(NMF\)**
* **Kernel PCA**
* **Graph-based kernel PCA**
* **Linear discriminant analysis \(LDA\)**
* **Generalized discriminant analysis \(GDA\)**

\*\*\*\*

â€Œ  


